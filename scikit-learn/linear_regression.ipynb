{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1450732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6751651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target Names: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "[ Data Information ]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   target             150 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.0 KB\n",
      "None\n",
      "\n",
      "[ Statistics ]\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            5.843333          3.057333           3.758000   \n",
      "std             0.828066          0.435866           1.765298   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.600000   \n",
      "50%             5.800000          3.000000           4.350000   \n",
      "75%             6.400000          3.300000           5.100000   \n",
      "max             7.900000          4.400000           6.900000   \n",
      "\n",
      "       petal width (cm)      target  \n",
      "count        150.000000  150.000000  \n",
      "mean           1.199333    1.000000  \n",
      "std            0.762238    0.819232  \n",
      "min            0.100000    0.000000  \n",
      "25%            0.300000    0.000000  \n",
      "50%            1.300000    1.000000  \n",
      "75%            1.800000    2.000000  \n",
      "max            2.500000    2.000000  \n",
      "\n",
      "[ Dataset ]\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     target  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "..      ...  \n",
      "145       2  \n",
      "146       2  \n",
      "147       2  \n",
      "148       2  \n",
      "149       2  \n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# load dataset and split features and targets \n",
    "data = load_iris()\n",
    "\n",
    "# convert to DataFrame\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# describe dataset\n",
    "print(f\"Feature Names: {data.feature_names}\")\n",
    "print(f\"Target Names: {data.target_names}\\n\")\n",
    "\n",
    "print(f\"[ Data Information ]\")\n",
    "print(df.info())\n",
    "print(f\"\\n[ Statistics ]\\n{df.describe()}\")\n",
    "print(f\"\\n[ Dataset ]\\n{df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20dc2958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split features and labels into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d62e87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict for model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaulate model\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "310eb8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===[ Evaluation ]===\n",
      "  Accuracy: 1.0000\n",
      " Precision: 1.0000\n",
      "    Recall: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# display model performance\n",
    "print(f\"{'[ Evaluation ]':=^20}\")\n",
    "print(f\"{'Accuracy':>10}: {accuracy:.4f}\")\n",
    "print(f\"{'Precision':>10}: {precision_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "print(f\"{'Recall':>10}: {recall_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "print(f\"{'F1 Score':>10}: {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "print(f\"{'':=^20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc6d1e1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dump() missing 1 required positional argument: 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# save model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogreg_iris.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: dump() missing 1 required positional argument: 'filename'"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "joblib.dump(model, 'logreg_iris.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
